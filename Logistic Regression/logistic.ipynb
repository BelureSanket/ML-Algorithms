import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression



df=pd.read_csv("student_data.csv")
df.head()

df.info()

feature_cols=['Marks 1','Marks 2']
X=df[feature_cols]
y=df.Admission
print(X.head())

print(y.head())

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)
X_train.shape

X_test.shape

from sklearn.linear_model import LogisticRegression
m1=LogisticRegression()
m1.fit(X_train,y_train)


y_pred=m1.predict(X_test)
y_test

y_pred

y_test


c1=metrics.confusion_matrix(y_test,y_pred)
print(c1)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

import numpy as np
import matplotlib.pyplot as plt
def logistic(x):
    return 1 / (1 + np.exp(-x))


x_values = np.linspace(-10, 10, 100)

y_values = logistic(x_values)
comb_marks=X_test['Marks 1']+X_test['Marks 2']
plt.plot(x_values, y_values, label='S-shaped Curve (Logistic Function)')
plt.scatter(comb_marks, y_pred, color='red', label='Predicted Probabilities (ypred)')
plt.title('S-shaped Curve with Predicted Probabilities')
plt.xlabel('Predicted Probabilities (ypred)')
plt.ylabel('Probability of Admission')
plt.legend()
plt.grid(True)
plt.show()

